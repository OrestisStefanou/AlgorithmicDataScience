{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XMhec7aVCrG",
        "outputId": "c3500732-5925-4d33-8c1d-5e7d49bd00fa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import gzip\n",
        "%matplotlib inline\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model,Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "import struct as st\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlOHefKYV6mq"
      },
      "source": [
        "def read_data(filename):\n",
        "    file = gzip.open(filename,'rb')\n",
        "    file.seek(0)\n",
        "    magic_number = st.unpack('>4B',file.read(4)) # read magic number\n",
        "    number_of_images = st.unpack('>I',file.read(4))[0] # read number of images\n",
        "    number_of_rows = st.unpack('>I',file.read(4))[0] #read number of rows\n",
        "    number_of_columns = st.unpack('>I',file.read(4))[0] #read number of column\n",
        "    with gzip.open(filename) as file_stream:\n",
        "        file_stream.read(16)\n",
        "        buf = file_stream.read(number_of_rows * number_of_columns * number_of_images)\n",
        "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
        "        data = data.reshape(number_of_images, number_of_rows,number_of_columns)\n",
        "        return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo_tZY7CV9I2"
      },
      "source": [
        "train_data = read_data('/content/train-images-idx3-ubyte.gz')\n",
        "test_data = read_data('/content/t10k-images-idx3-ubyte.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNNj-GLKWAPS"
      },
      "source": [
        "def read_labels(filename):\n",
        "    file = gzip.open(filename,'rb')\n",
        "    file.seek(0)\n",
        "    magic_number = st.unpack('>4B',file.read(4)) # read magic number\n",
        "    number_of_iteams = st.unpack('>I',file.read(4))[0] # read number of images\n",
        "    with gzip.open(filename) as file_stream:\n",
        "        file_stream.read(8)\n",
        "        buf = file_stream.read(number_of_iteams)\n",
        "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
        "        return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6NIQSXoWC8U"
      },
      "source": [
        "train_labels = read_labels('/content/train-labels-idx1-ubyte.gz')\n",
        "test_labels = read_labels('/content/t10k-labels-idx1-ubyte.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F61oe_qagSol"
      },
      "source": [
        "# Create dictionary of target classes\n",
        "label_dict = {\n",
        " 0: '0',\n",
        " 1: '1',\n",
        " 2: '2',\n",
        " 3: '3',\n",
        " 4: '4',\n",
        " 5: '5',\n",
        " 6: '6',\n",
        " 7: '7',\n",
        " 8: '8',\n",
        " 9: '9',\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgKN3Nb_gWHG",
        "outputId": "5e8754ce-94ad-46e5-89e2-ee33a57b0be5"
      },
      "source": [
        "train_data = train_data.reshape(-1, 28,28, 1)\n",
        "test_data = test_data.reshape(-1, 28,28, 1)\n",
        "train_data.shape, test_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (10000, 28, 28, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdtTiViwgZVq"
      },
      "source": [
        "train_data = train_data / np.max(train_data)\n",
        "test_data = test_data / np.max(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihw7P9wdgcsh"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,\n",
        "                                                             train_data,\n",
        "                                                             test_size=0.2,\n",
        "                                                             random_state=13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-z-mIq7ggB1"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 25\n",
        "inChannel = 1\n",
        "x, y = 28, 28\n",
        "input_img = Input(shape = (x, y, inChannel))\n",
        "num_classes = 10\n",
        "n_inputs = train_data.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M0CND16gihF"
      },
      "source": [
        "\n",
        "#encoder\n",
        "#input = 28 x 28 x 1 (wide and thin)\n",
        "conv1 = Conv2D(32, (3, 3), activation='softmax', padding='same')(input_img) #28 x 28 x 32\n",
        "conv1 = BatchNormalization()(conv1)\n",
        "conv1 = Conv2D(32, (3, 3), activation='softmax', padding='same')(conv1)\n",
        "conv1 = BatchNormalization()(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
        "conv2 = Conv2D(64, (3, 3), activation='softmax', padding='same')(pool1) #14 x 14 x 64\n",
        "conv2 = BatchNormalization()(conv2)\n",
        "conv2 = Conv2D(64, (3, 3), activation='softmax', padding='same')(conv2)\n",
        "conv2 = BatchNormalization()(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
        "conv3 = Conv2D(128, (3, 3), activation='softmax', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
        "conv3 = BatchNormalization()(conv3)\n",
        "conv3 = Conv2D(128, (3, 3), activation='softmax', padding='same')(conv3)\n",
        "conv3 = BatchNormalization()(conv3)\n",
        "conv4 = Conv2D(256, (3, 3), activation='softmax', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n",
        "conv4 = BatchNormalization()(conv4)\n",
        "conv4 = Conv2D(256, (3, 3), activation='softmax', padding='same')(conv4)\n",
        "conv4 = BatchNormalization()(conv4)\n",
        "# bottleneck\n",
        "n_bottleneck = round(float(n_inputs) / 2.0)\n",
        "bottleneck = Dense(n_bottleneck)(conv4)\n",
        "\n",
        "#decoder\n",
        "conv5 = Conv2D(256, (3, 3), activation='softmax', padding='same')(bottleneck) #7 x 7 x 128\n",
        "conv5 = BatchNormalization()(conv5)\n",
        "conv5 = Conv2D(256, (3, 3), activation='softmax', padding='same')(conv5)\n",
        "conv5 = BatchNormalization()(conv5)\n",
        "conv6 = Conv2D(128, (3, 3), activation='softmax', padding='same')(conv5) #7 x 7 x 64\n",
        "conv6 = BatchNormalization()(conv6)\n",
        "conv6 = Conv2D(128, (3, 3), activation='softmax', padding='same')(conv6)\n",
        "conv6 = BatchNormalization()(conv6)\n",
        "up1 = UpSampling2D((2,2))(conv6) #14 x 14 x 64\n",
        "conv7 = Conv2D(64, (3, 3), activation='softmax', padding='same')(up1) # 14 x 14 x 32\n",
        "conv7 = BatchNormalization()(conv7)\n",
        "conv7 = Conv2D(64, (3, 3), activation='softmax', padding='same')(conv7)\n",
        "conv7 = BatchNormalization()(conv7)\n",
        "    \n",
        "up2 = UpSampling2D((2,2))(conv7) # 28 x 28 x 32\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlYIxF0vh0Fl"
      },
      "source": [
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHG5dAdGh33P",
        "outputId": "04481aff-483d-4844-eae8-6838fba322c2"
      },
      "source": [
        "autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "  2/375 [..............................] - ETA: 9s - loss: 0.2285WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0157s vs `on_train_batch_end` time: 0.0362s). Check your callbacks.\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0508 - val_loss: 0.1085\n",
            "Epoch 2/25\n",
            "375/375 [==============================] - 21s 56ms/step - loss: 0.0138 - val_loss: 0.0783\n",
            "Epoch 3/25\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0086 - val_loss: 0.0131\n",
            "Epoch 4/25\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0064 - val_loss: 0.0080\n",
            "Epoch 5/25\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0052 - val_loss: 0.0048\n",
            "Epoch 6/25\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0044 - val_loss: 0.0033\n",
            "Epoch 7/25\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0039 - val_loss: 0.0032\n",
            "Epoch 8/25\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0035 - val_loss: 0.0029\n",
            "Epoch 9/25\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0031 - val_loss: 0.0031\n",
            "Epoch 10/25\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 11/25\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0027 - val_loss: 0.0037\n",
            "Epoch 12/25\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0026 - val_loss: 0.0021\n",
            "Epoch 13/25\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0024 - val_loss: 0.0020\n",
            "Epoch 14/25\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 15/25\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 16/25\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 17/25\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 18/25\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 19/25\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 20/25\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 21/25\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 22/25\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 23/25\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 24/25\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 25/25\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0016 - val_loss: 0.0019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx-p74w0nnhi"
      },
      "source": [
        "# define an encoder model (without the decoder)\n",
        "encoder = Model(inputs=input_img, outputs=bottleneck)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybsYl838jOFM"
      },
      "source": [
        "# encode the train data\n",
        "X_train_encode = encoder.predict(train_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q4Y14fpjUfq",
        "outputId": "b428be28-3080-43a9-f100-225ad0651782"
      },
      "source": [
        "print(len(X_train_encode[10]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3HN2fwHjYMM",
        "outputId": "9b7844cf-e1e7-4f34-86c0-fe2764ade17c"
      },
      "source": [
        "print(len(train_X[10]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxNPngYtkUv1"
      },
      "source": [
        "Na filaksoume tis nees eikones se file gia na tis diavasoume meso tis c++"
      ]
    }
  ]
}